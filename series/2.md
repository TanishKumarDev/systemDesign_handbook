# Beginner-Friendly Guide to System Design: Part 2 - Scalability and Advanced Components

This guide builds on Part 1, focusing on scalability challenges, traffic patterns, serverless architecture, containerization (Docker), and orchestration (Kubernetes). It explains how systems evolve for fault tolerance, cost optimization, and handling real-world variability, using examples like Netflix, YouTube, and Hotstar.

## Recap from Part 1
- **Core Components**: Client-server model, DNS resolution, vertical/horizontal scaling, load balancers, API Gateway, microservices.
- **Async Processing**: Queue systems (SQS), pub/sub (SNS), fan-out architecture, dead letter queues, bulk workers.
- **Optimization**: Rate limiting, database read replicas, caching (Redis), CDN (CloudFront) for global distribution and latency reduction.
- **Key Insight**: These form a scalable, robust foundation, but real systems evolve based on unique needs.

## Why System Design Evolves
- **Not One-Size-Fits-All**: Every company has unique use cases, USPs, workflows, and traffic patterns.
- **End Goals**:
  - Full scalability and fault tolerance (no crashes under high load).
  - Cost optimization (scale efficiently without over-provisioning).
- **Balance**: Easy to over-scale (high cost); system design strikes a balance via monitoring and iteration.
- **Process**: Start simple, monitor crashes/spikes, learn from failures, optimize iteratively.

## Understanding Traffic Patterns
Traffic patterns dictate design choices. Even similar apps (e.g., video streaming) need tailored systems.

### Netflix: Predictable Spikes
- **Pattern**: Steady ~3M active users globally; spikes on movie releases (trailer hype builds predictability).
- **Graph Simulation**: Gradual growth with occasional bursts; historical data (10+ years) predicts spikes.
- **Handling**:
  - **Pre-Scaling**: 24 hours before release, warm up servers (e.g., from 10 to 30 replicas).
  - **Caching**: Pre-cache first 10 minutes of movie on global CDN edges—reduces origin server load.
  - **Policies**: Auto-scale on metrics (e.g., CPU >70%, requests >1000/15min), but pre-warm for known events.
- **Why Easy?**: Netflix controls releases; spikes are scheduled, not random.

### YouTube: Unpredictable Spikes
- **Pattern**: Average ~10-50M users; sudden 10x spikes from viral content (e.g., MrBeast live) or events (e.g., political news).
- **Challenges**: Publishing is user-driven (no prior notice); hard to predict exact timing.
- **Partial Prediction**: Use ML for trends (e.g., exam season spikes for study content; festival dips like Diwali).
- **Handling**:
  - **Pre-Warming**: Keep servers warm despite cost—handles bursts without averages-based delays.
  - **Advanced Design**: Auto-scaling on real-time metrics, but relies on robust infrastructure for 10x jumps.
- **Why Hard?**: External triggers (creators/news); monthly predictions possible, but daily/hourly spikes aren't.

### Hotstar: Mixed Predictable and Unpredictable
- **Services**: Two microservices—Movie Catalog (steady) and Live Streaming (event-driven, e.g., cricket).
- **Pattern**:
  - Steady: Movie/web series consumption.
  - Predictable: Match days (e.g., India vs. rival)—pre-scale live service (10 → 200 replicas 1-2 hours before).
  - Unpredictable: In-match spikes (e.g., wicket falls, Virat Kohli bats—WhatsApp buzz drives views); dips (boring overs → users leave).
- **Graph Simulation**:
  - Low baseline; toss → spike; boring phase → dip; key moment → spike; end → gradual drop.
- **Handling**:
  - **Disable Auto-Scaling During Events**: Keep 200 servers running for 4-6 hours (cost for fault tolerance > optimization).
  - **Scale Services Independently**: Scale down movies during matches (few viewers); scale up live streaming.
  - **Correlations**: Dips in live = spikes elsewhere (e.g., back button → home screen loads Movie API for 240M users → sudden 240M calls).
    - Solution: Keep Movie service scaled during events—anticipate "back button storms."
- **Why Tricky?**: Hybrid patterns; auto-scaling oscillates (dip → scale down → sudden spike → crash); simulate via load/stress testing day before.

### Key Takeaway on Patterns
- Monitor historical data; learn from crashes (e.g., Hotstar's early back-button oversight).
- Amazon Example: Predict Big Billion Days; pre-scale, but still vulnerable to YouTube-like virality.
- **Universal Advice**: No universal design—tailor to patterns; start simple, iterate.

## Serverless Architecture (e.g., AWS Lambda)
- **What It Is**: "Serverless" ≠ no servers; cloud manages infrastructure—you deploy code (e.g., JS file) via functions.
  - AWS creates public URL (e.g., https://abc.com); invokes code per request.
  - Auto-scales: 1 Lambda/request; spins up/destroys dynamically.
- **Evolution Driver**: Traditional servers have setup overhead (OS, CPU/RAM config, IP allocation, load balancer registration)—distracts from app dev.

### Pros
- **Cheap/Pay-Per-Use**: Free tier (1M requests + 3.2M compute seconds/month); ~$0.20/M requests after.
  - No idle costs (zero users = zero pay); profitable even at 10-20M requests/month.
- **No Overhead**: No scaling policies, configs, or management—focus on code.
- **Auto-Everything**: Scaling, load balancing handled by cloud.

### Cons and Trade-Offs
- **Cold Starts**: First request after idle (e.g., overnight) warms Lambda (2s latency); subsequent fast (0.5s). Mitigated by continuous traffic.
- **Fixed Duration**: ≤15s/response (API Gateway limit)—not for long tasks.
- **DDoS Vulnerability**: Unlimited scaling under attack → runaway costs.
- **Vendor Lock-In**: Code tied to AWS; migration requires rewrite. Ecosystem pull (SQS, API Gateway, S3, CloudWatch, Step Functions) → full AWS dependency, inflating costs.
- **Stateless**: No session state (destroyed post-request); can't store user data in-memory.
- **DB Connections**: Each Lambda connects to DB (e.g., MongoDB) → connection storms under load; need reverse proxy for pooling (adds EC2 overhead).
- **Production Reality**: Seems simple in dev; scales poorly at high traffic—single failure point if Lambda host overloads.

## Traditional Servers (Serverful)
- **Setup Overhead**: Static IP, fixed CPU/RAM, auto-scaling group, load balancer.
- **Scaling Issues**:
  - Dependencies (e.g., FFmpeg for video): New replicas need install scripts (sudo apt update/install)—delays during spikes → crashes.
  - "It Works on My Machine": Local (Windows/Mac) vs. prod (Ubuntu) mismatches (versions, binaries, 30-40 libs).
- **Result**: Focus shifts from app to infra; scaling feels "heavy" (full OS boot).

## Virtualization (VMs)
- **Solution to Dependencies**: Create VM image locally (e.g., Ubuntu + FFmpeg + code); deploy entire image.
  - Ensures "It works on my machine" → prod consistency.
- **How**: Run VM inside host OS; install deps inside VM; snapshot/deploy.
- **Cons**:
  - Heavy: Full guest OS (4-5GB) + host OS → high resource use (needs >2 CPU/4GB).
  - Slow Scaling: Boot time for OS image during spikes.
- **Trade-Off**: Solves env mismatches but increases cost/complexity.

## Containerization (Docker)
- **What It Is**: Lightweight VMs—remove guest OS; share host kernel.
  - Size: ~250MB (packages + code only; OS ~4GB saved).
  - Isolation: Each container runs code/packages independently.
- **Benefits**:
  - **Easy Scaling**: Spin/create/destroy quickly; run 15-16 on one machine.
  - **Consistency**: Build/test locally → deploys identically.
  - **Resource Efficient**: Multiple on few physical machines; pay for 2 machines, run 16+ containers.
- **Example**: During spike, launch 10-15 containers across machines—seamless, no full OS overhead.
- **Overhead Introduced**: Managing many containers (health, scaling, updates) needs a "brain."

## Container Orchestration
- **Need**: Automate deployment, scaling, management across server clusters (e.g., 3 servers, 30+ containers).
  - Tasks: Auto-scale on traffic, health checks (restart red containers), rolling updates (replace old with new zero-downtime), blue-green deployments.
- **Challenges**: Track 50 containers; handle errors, traffic shifts, version rollouts.

### Kubernetes (K8s)
- **Origin**: Google's internal Borg (cluster manager for data centers) inspired it.
  - Rewritten as open-source project (Project X); donated to CNCF (Cloud Native Computing Foundation).
  - Maintained by global community; Google drew from Borg learnings (Promise Theory).
- **What It Does**: Automates container lifecycle—deployment, scaling, management.
  - Components: Control Plane (API Server, etcd, Scheduler, Controller Manager); Worker Nodes (Kubelet, Kube Proxy); Pods (container groups).
- **Features**:
  - Auto-scaling/load balancing.
  - Zero-downtime updates (rolling/blue-green).
  - Ingress/egress controllers, reverse proxies.
- **Why Popular?**: Open-source, cloud-agnostic; handles massive scale (e.g., Hotstar's 240M cricket viewers).
- **Resources**: Dedicated video on K8s components (link in description).

## Modern System Design
- **Stack**: Containers (Docker) + Orchestrator (Kubernetes) for balance.
  - Pros: Fast scaling, zero-downtime, easy updates; open-source (no vendor lock beyond cloud).
- **Evolution Path**:
  - Traditional Servers → VMs (dependency fix, heavy) → Containers (lightweight) → Orchestration (management brain).
- **Behind-the-Scenes**: Load testing/stress testing (simulate traffic day before events); handles seamless 4K streaming via CDN + engineering.

## Conclusion
System design is iterative: Understand patterns, evolve from serverful to serverless/containers/K8s. Big platforms (Hotstar, YouTube) invest in simulations/crashes for smooth experiences. Share thoughts on topics for future videos!