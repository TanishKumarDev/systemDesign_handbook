# Caching in System Design

**Definition:**
Caching is the process of storing **frequently accessed data** in a fast-access location so that future requests for the same data can be served **quickly** without hitting the main database.

üí° Analogy: Think of cache as a **local memory desk**‚Äîinstead of going to the library (database) every time, you keep the most used books (data) on your desk for quick access.

---

## How Cache Works

1. **First Request ‚Üí Cache Miss**

   * User requests data.
   * Cache checks ‚Üí data not found ‚Üí fetch from database.
   * Store the result in cache.

2. **Subsequent Request ‚Üí Cache Hit**

   * Next time the same request comes ‚Üí data served **from cache**.
   * Much faster than database query.

üìå Example:
Twitter viral tweet ‚Üí many users request same data ‚Üí cache serves it ‚Üí reduces DB load ‚Üí faster response.

---

## Why Not Store Everything in Cache?

* Cache memory is **expensive** compared to DB.
* Too much data ‚Üí slower searches.
* Cache is **volatile** ‚Üí data lost if system crashes.
* Only **relevant/frequently accessed data** should be cached.

---

## Types of Cache

### 1Ô∏è‚É£ Application Server Cache

* Local to each server.
* Stores frequently used data for that server.
* **Drawback:** In multi-server setups, cache is not shared ‚Üí many cache misses.

### 2Ô∏è‚É£ Distributed Cache

* Cache is **split across nodes** using **consistent hashing**.
* Each node knows which data it has ‚Üí quick access.
* Solves multi-server cache miss problem.

### 3Ô∏è‚É£ Global Cache

* Single cache shared by all nodes.
* All requests go to this cache first.
* **If not found** ‚Üí fetch from DB.
* Two strategies:

  1. Cache fetches missing data from DB automatically.
  2. Requesting node fetches from DB if cache misses.

### 4Ô∏è‚É£ CDN (Content Delivery Network)

* Geographically distributed servers storing **static content**.
* Requests served from **nearest server** ‚Üí faster content delivery.
* Example: Images, videos, HTML, CSS, JS.

---

## Applications of Caching

| Type                 | Use Case                                            |
| -------------------- | --------------------------------------------------- |
| Web Page Caching     | Browser saves pages ‚Üí faster load                   |
| Database Caching     | Frequently queried DB data ‚Üí faster retrieval       |
| CDN                  | Global content delivery ‚Üí lower latency             |
| Session Caching      | Store user login/session data ‚Üí seamless experience |
| API Response Caching | Stock prices, weather data ‚Üí real-time performance  |

---

## Cache Invalidation

* Cached data can become **stale** if DB changes.
* **Strategies:**

  1. **Time-based**: Expire after X seconds/minutes.
  2. **Event-driven**: Invalidate when underlying data changes.

---

## Eviction Policies

* When cache is full ‚Üí need to remove items:

  * **LRU (Least Recently Used)** ‚Üí remove least recently accessed.
  * **LFU (Least Frequently Used)** ‚Üí remove least used items.
  * **FIFO (First In First Out)** ‚Üí remove oldest items.

---

## Pros of Caching

* Faster system performance ‚úÖ
* Reduces DB/server load ‚úÖ
* Cost savings on infrastructure ‚úÖ

## Cons of Caching

* Data inconsistency if not managed ‚úÖ
* Poor eviction policy ‚Üí performance issues ‚úÖ
* Adds system complexity ‚úÖ
---

# Caching Strategies for API

**Definition:**
Caching stores frequently accessed API data temporarily to serve future requests faster, reduce server load, improve scalability, and enhance reliability.

üí° Analogy: Cache is like keeping a copy of a frequently used book on your desk instead of fetching it from the library every time.

---

## Importance of API Caching

| Benefit                         | Description                                           |
| ------------------------------- | ----------------------------------------------------- |
| **Improved Performance**        | Data closer to user ‚Üí faster responses                |
| **Reduced Server Load**         | Fewer requests reach the server ‚Üí less processing     |
| **Enhanced Scalability**        | Handles more traffic without extra servers            |
| **Increased Availability**      | Data can be served during server/network failures     |
| **Reduced Latency**             | Cache access faster than database/external service    |
| **Resource Optimization**       | Saves CPU, memory, and network bandwidth              |
| **Decreased API Rate Limiting** | Fewer direct API calls ‚Üí avoids throttling            |
| **Horizontal Scaling**          | Cached data can be distributed across servers/regions |

---

## How API Caching Improves Performance

1. **Faster Data Retrieval** ‚Üí Reduced response time.
2. **Reduced Database Load** ‚Üí Fewer DB queries.
3. **Minimized Network Latency** ‚Üí Data closer to requestor.
4. **Enhanced Throughput** ‚Üí More requests handled per second.
5. **Improved User Experience** ‚Üí Quick, reliable responses.
6. **Resource Optimization** ‚Üí Efficient hardware utilization.
7. **Decreased API Rate Limiting** ‚Üí Smooth API availability.
8. **Scalability** ‚Üí Easier horizontal scaling across regions.

---

## How Caching Reduces Server Load

* Serve repeated requests from cache.
* Reduce database queries.
* Avoid recomputation of expensive operations.
* Absorb traffic spikes ‚Üí prevents overload.
* Free servers for dynamic tasks ‚Üí improves reliability.

---

## Types of API Caching Mechanisms

| Type                  | Examples                                     | Benefits                                     | Use Cases                                    |
| --------------------- | -------------------------------------------- | -------------------------------------------- | -------------------------------------------- |
| **Client-Side**       | Browser Cache (Cache-Control, ETag, Expires) | Reduces server load, low latency             | Static assets, infrequently changed API data |
| **Server-Side**       | Redis, Memcached                             | Fast in-memory access, reduces recomputation | Product catalogs, news feeds                 |
| **Reverse Proxy**     | Nginx, Varnish                               | Caches responses at network edge             | Public APIs, high-traffic content            |
| **Distributed**       | Couchbase, Amazon ElastiCache                | Scalable, fault-tolerant                     | Large-scale applications, high availability  |
| **Application-Level** | Local HashMaps, Guava                        | Customizable per application logic           | Fine-grained caching, data freshness control |
| **Database Caching**  | Redis, Memcached                             | Offloads DB queries, improves DB performance | Frequently queried tables, complex queries   |

---

## Popular Caching Strategies

### 1Ô∏è‚É£ Cache-Aside (Lazy Loading)

* On request: Check cache ‚Üí miss ‚Üí fetch from DB ‚Üí store in cache.
* Only requested data is cached ‚Üí saves memory.
* Flexible expiration ‚Üí custom logic for invalidation.
* Best for **read-heavy workloads** with moderately dynamic data.

### 2Ô∏è‚É£ Write-Through

* On write: Data written to both cache and DB simultaneously.
* Ensures cache consistency.
* Simplifies cache management.
* Best for **write-heavy workloads** and critical consistency.

---

## Real-World Examples

| Company     | Caching Strategy                      | Use Case                      | Benefit                               |
| ----------- | ------------------------------------- | ----------------------------- | ------------------------------------- |
| **Twitter** | Cache-Aside, In-Memory (Memcached)    | Timelines, user sessions      | Fast retrieval, reduced DB load       |
| **Netflix** | Distributed + Write-Through (EVCache) | Metadata, user data           | Quick access, high availability       |
| **Amazon**  | CDN + Cache-Aside (CloudFront + DAX)  | Static assets, DynamoDB reads | Low latency, fast shopping experience |

---
